# Importing Packages
import pefile
import pip
import sklearn
import pickle

# Importing libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from keras.applications.densenet import layers
from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier
from sklearn import tree, linear_model
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import SelectFromModel
from sklearn.metrics import confusion_matrix
from sklearn.datasets import make_classification
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
#print(tf.__version__)

# Importing the dataset
data = pd.read_csv("MalwareData.csv", sep='|')

leg = data[0:41323].drop(['legitimate'], axis=1)
mal = data[41323::].drop(['legitimate'], axis=1)

print("Size of legitimate files are: %i samples, %i features" % (leg.shape[0], leg.shape[1]))
print("Size of Malware files are: %i samples, %i features" % (mal.shape[0], mal.shape[1]))
print("Total important samples are: %i samples" % data.shape[0], '\n')

print(data.columns, '\n')
pd.set_option("display.max_columns", None)
print(data.head, '\n')
print(leg.take, '\n')
print(mal.take, '\n')

# Coding and Feature Selection using tree Classifier
x = data.drop(['Name', 'md5', 'legitimate'], axis=1).values
y = data['legitimate'].values
classifier = ExtraTreesClassifier().fit(x, y)
model = SelectFromModel(classifier, prefit=True)
x_new = model.transform(x)
print(x.shape, x_new.shape, '\n')
features = x_new.shape[1]
important = classifier.feature_importances_

# Splitting the dataset into the Training set and Test set
x_train, x_test, y_train, y_test = train_test_split(x_new, y, test_size=0.2)
print('features identified as important:')
indices = np.argsort(important)[::-1]

for f in range(features):
    print("%d. feature %s (%f)" % (f + 1, data.columns[2 + indices[f]], important[indices[f]]), "\n")

# Classifier Comparison
classifier = ExtraTreesClassifier(max_depth=10)
classifier.fit(x_train, y_train)
print("The DecisionTree score is: ", classifier.score(x_test, y_test) * 100)
y_pred = classifier.predict(x_test)
mt = confusion_matrix(y_test, y_pred)
print("False positive rate : %f %%" % ((mt[0][1] / float(sum(mt[0])))*100))
print('False negative rate : %f %%' % ((mt[1][0] / float(sum(mt[1]))*100)))
g = pd.DataFrame(mt)
g
plt.title('Confusion matrix of Decision Tree')
print(mt)
mal = sns.heatmap(mt ,annot=True,linewidths=1 ,cmap = "Blues", linewidth = 1 ,linecolor='k')
plt.xlabel('Predicted label')
plt.ylabel('True label')
plt.show()

classifier = RandomForestClassifier(n_estimators=50)
classifier.fit(x_train, y_train)
print("The RandomForest score is: ", classifier.score(x_test, y_test) * 100, '\n')
classifier = RandomForestClassifier(n_estimators=50)
classifier.fit(x_train, y_train)
print("The RandomForest score is: ", classifier.score(x_test, y_test)*100)
y_pred = classifier.predict(x_test)
mt = confusion_matrix(y_test, y_pred)
print("False positive rate : %f %%" % ((mt[0][1] / float(sum(mt[0])))*100))
print('False negative rate : %f %%' % ((mt[1][0] / float(sum(mt[1]))*100)))
g = pd.DataFrame(mt)
g
plt.title('Confusion matrix of Random Forest')
print(mt)
mal = sns.heatmap(mt ,annot=True,linewidths=1 ,cmap = "Blues", linewidth = 1 ,linecolor='k')
plt.xlabel('Predicted label')
plt.ylabel('True label')
plt.show()

algorithms = {
        "DecisionTree": ExtraTreesClassifier(max_depth=10),
        "RandomForest": RandomForestClassifier(n_estimators=50)
}

results = {}
print("\nNow testing algorithms")
for algo in algorithms:
    classifier = algorithms[algo]
    classifier.fit(x_train, y_train)
    score = classifier.score(x_test, y_test)
    print("%s : %f %%" % (algo, score*100))
    results[algo] = score

winner = max(results)
print('\nWinner algorithm is %s with a %f %% success' % (winner, results[winner]*100))

# Save the algorithm and the feature list for later predictions
print('Saving algorithm and feature list in classifier directory...')

with open('Classifier/classifier.pkl', 'wb') as pickle_file:
    pickle.dump(classifier.score, pickle_file)

with open('Classifier/classifier.pkl', 'rb') as pickle_file:
    new_data = pickle.load(pickle_file)

y_pred = classifier.predict(x_test)
mt = confusion_matrix(y_test, y_pred)
print("False positive rate : %f %%" % ((mt[0][1] / float(sum(mt[0])))*100))
print('False negative rate : %f %%' % ((mt[1][0] / float(sum(mt[1])))*100))

g = pd.DataFrame(mt)
g

#Neural Network
model = Sequential([
    Dense(32, activation='relu', input_shape=(len(x_new[1]),)),
    Dense(32, activation='relu'),
    Dense(1, activation='sigmoid'),
])
model.summary()

model.compile(loss="binary_crossentropy", optimizer="adam", metrics=["accuracy"])
print(x_train.shape)
model.fit(x_train, y_train, batch_size=32, epochs=5, verbose=1)

#Accuracy On training and Testing Models
model.evaluate(x_test, y_test)[1]
model.evaluate(x_train, y_train)[1]

scores = model.evaluate(x_train, y_train)
print("\n%s: %.2f%%" % (model.metrics_names[1], scores[1]*100))
scores = model.evaluate(x_test, y_test)
print("\n%s: %.2f%%" % (model.metrics_names[1], scores[1]*100))