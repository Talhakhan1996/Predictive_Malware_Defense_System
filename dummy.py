import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import pickle
import seaborn as sns
from keras import Sequential
from keras.layers import Dense
from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier
from sklearn import tree, linear_model
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import SelectFromModel
from sklearn.metrics import confusion_matrix, plot_confusion_matrix
from sklearn.datasets import make_classification
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

data = pd.read_csv("MalwareData.csv", sep='|')

leg = data[0:41323].drop(['legitimate'], axis=1)
mal = data[41323::].drop(['legitimate'], axis=1)

print("Size of legitimate files are: %i samples, %i features" % (leg.shape[0], leg.shape[1]))
print("Size of Malware files are: %i samples, %i features" % (mal.shape[0], mal.shape[1]))
print("Total important samples are: %i samples" % data.shape[0], '\n')

# Coding and Feature Selection using tree Classifier
x = data.drop(['Name', 'md5', 'legitimate'], axis=1).values
print(x.shape)
y = data['legitimate'].values
classifier = ExtraTreesClassifier().fit(x, y)
model = SelectFromModel(classifier, prefit=True)
x_new = model.transform(x)
print(x.shape, x_new.shape, '\n')
features = x_new.shape[1]
important = classifier.feature_importances_

# Splitting the dataset into the Training set and Test set
x_train, x_test, y_train, y_test = train_test_split(x_new, y, test_size=0.2)
print('features identified as important:')
indices = np.argsort(important)[::-1]


model = Sequential([
    Dense(32, activation='relu', input_shape=(len(x_new[1]),)),
    Dense(32, activation='relu'),
    Dense(1, activation='sigmoid'),
])
model.summary()

model.compile(loss="binary_crossentropy", optimizer="adam", metrics=["accuracy"])
print(x_train.shape)
model.fit(x_train, y_train, batch_size=32, epochs=5, verbose=1)